{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecdfd6e-55a4-40f3-8c93-320d439e13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What is a parameter?\n",
    "\n",
    "# Ans - A parameter is a variable used to define or pass information, and its meaning can vary slightly depending on the context. Here are a few common\n",
    "#       definitions.\n",
    "\n",
    "#      In code, parameters are inputs to functions.\n",
    "#      In math, they define how a function behaves.\n",
    "#      In statistics, they describe characteristics of an entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d142e-91d7-43ad-afc5-6165c99e69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is correlation?\n",
    "\n",
    "# Ans - Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
    "\n",
    "#       Positive correlation: When one variable increases, the other tends to increase.\n",
    "#       Example: Height and weight — generally, taller people weigh more.\n",
    "\n",
    "#       Negative correlation: When one variable increases, the other tends to decrease.\n",
    "#       Example: The more hours you spend watching TV, the lower your exam score might be.\n",
    "\n",
    "#       No correlation: No consistent pattern between the two variables.\n",
    "#       Example: Shoe size and intelligence.\n",
    "\n",
    "#       What does negative correlation mean?\n",
    "\n",
    "#      Negative correlation means that as one variable increases, the other variable tends to decrease — and vice versa. In other words, they move in \n",
    "#      opposite directions.\n",
    "\n",
    "#      Real-Life Examples:\n",
    "#      Exercise vs. Body Fat: More exercise → less body fat.\n",
    "#      Speed vs. Travel Time: Higher speed → less time to reach your destination.\n",
    "#      Absenteeism vs. Grades: More days missed from school → lower grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70c33d-006f-4855-b29a-3e37b4c080fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Machine Learning. What are the main components in Machine Learning?\n",
    "\n",
    "# Ans - Machine Learning is a branch of artificial intelligence (AI) that focuses on developing algorithms and systems that can learn from data and make\n",
    "#       decisions or predictions without being explicitly programmed for every specific task.\n",
    "\n",
    "#      Main Components of Machine Learning:\n",
    "#      1. Data\n",
    "#         The foundation of machine learning.\n",
    "#         Includes input features (independent variables) and output labels (dependent variables in supervised learning).\n",
    "#      2. Model (Algorithm)\n",
    "#         A mathematical structure or method used to learn patterns from data.\n",
    "#      3. Features\n",
    "#         Individual measurable properties or characteristics of the data.\n",
    "#      4. Learning Algorithm\n",
    "#         The process that adjusts the model’s internal parameters to minimize errors.\n",
    "#      5. Training\n",
    "#         The process of feeding data to the algorithm so it can learn.\n",
    "#      6. Prediction\n",
    "#         Once trained, the model is used to make predictions or decisions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b99300-0da3-444d-9db9-9da12f4094fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. How does loss value help in determining whether the model is good or not?\n",
    "\n",
    "# Ans - The loss value is a key indicator of how well a machine learning model is performing — it measures the difference between the model's predictions\n",
    "#       and the actual values (ground truth).\n",
    "\n",
    "#       A loss function computes a numerical value (called the loss) for each prediction.\n",
    "#       Lower loss = predictions are closer to the true values.\n",
    "#       Higher loss = model is making bigger errors.\n",
    "\n",
    "#       The Summary of the loss value are\n",
    "#       Loss = performance measure (how \"wrong\" the model is).\n",
    "#       Smaller loss = better model.\n",
    "#       Used to train, evaluate, and improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4e317-fc33-4f88-9316-0a5f6872d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. What are continuous and categorical variables?\n",
    "\n",
    "# Ans - In data analysis and machine learning, understanding the types of variables is essential. Two of the most common types are continuous and\n",
    "#       categorical variables.\n",
    "\n",
    "#      1. Continuous Variables:\n",
    "#      These are numerical values that can take any value within a range.\n",
    "#      They are typically measurable and can have decimal values.\n",
    "\n",
    "#      2. Categorical Variables:\n",
    "#      These are variables that represent categories or groups.\n",
    "#      They contain a finite number of distinct values or labels.\n",
    "\n",
    "#       Feature\t                             Continuous Variable\t                                    Categorical Variable\n",
    "#      Data type\t                       Numerical (often floats)\t                                    Labels or categories\n",
    "#    Value range\t                       Infinite (within range)\t                                    Finite\n",
    "#   Can be ordered?\t                       Yes\tOrdinal:                                                Yes, Nominal: No\n",
    "#   Math operations?\t                   Yes\t                                                        No\n",
    "#      Examples\t                           Height, Weight, Temperature\t                                Gender, Country, Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb61b7ae-952d-40f8-bb6f-de3b11e091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
    "\n",
    "# Ans - Handling categorical variables properly is crucial in machine learning, because most algorithms require numerical input. Categorical data must \n",
    "#       be converted into a format that ML models can understand.\n",
    "\n",
    "#       1.Label Encoding\n",
    "#         Converts each category into a unique integer.\n",
    "#         Best for ordinal data (categories with a meaningful order)\n",
    "\n",
    "#       2.One-Hot Encoding\n",
    "#         Converts categories into binary columns (0 or 1).\n",
    "#         Ideal for nominal data.\n",
    "\n",
    "#       3.Target Encoding (Mean Encoding)\n",
    "#         Replaces each category with the mean of the target variable for that category.\n",
    "#         Useful for high-cardinality categorical variables.\n",
    "\n",
    "#       4.Binary Encoding / Hash Encoding\n",
    "#         Combines the benefits of one-hot and label encoding.\n",
    "#         Useful for high-cardinality features (e.g., thousands of unique product IDs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07298056-8b2b-4a4e-af2e-47e8990db673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What do you mean by training and testing a dataset?\n",
    "\n",
    "# Ans - In machine learning, training and testing refer to how we split the data and use it to build and evaluate a model.\n",
    "\n",
    "#       1. Training Dataset\n",
    "#          The training dataset is the part of your data used to teach the model.\n",
    "#          The model learns patterns, relationships, and rules from this data.\n",
    "#          This is where the algorithm adjusts its internal parameters (like weights in a neural network) to minimize error.\n",
    "\n",
    "#       2. Testing Dataset\n",
    "#          The testing dataset is never seen by the model during training.\n",
    "#          It is used to evaluate how well the model generalizes to new, unseen data.\n",
    "#          It gives a realistic estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d2f0f-8266-4e5f-aa60-a6a6e7c0e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. What is sklearn.preprocessing?\n",
    "\n",
    "# Ans - sklearn.preprocessing is a module in Scikit-learn (a popular Python machine learning library) that provides tools for preprocessing data before \n",
    "#       it's fed into a machine learning model.Think of it as a data cleaning and transformation toolkit that helps improve the performance and accuracy\n",
    "#       of ML models.\n",
    "\n",
    "#       a) sklearn.preprocessing is used to clean, scale, and transform your data.\n",
    "#       b) It helps prepare your dataset to ensure better model performance and compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73553c2-b25c-4ad6-ba62-fb1159f9d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. What is a Test set?\n",
    "\n",
    "# Ans - A test set is a subset of your dataset that you use to evaluate the final performance of your machine learning model after training.\n",
    "\n",
    "#       Key Purpose:\n",
    "#       To assess how well the model performs on new, unseen data — which is critical for understanding how it will work in the real world.\n",
    "\n",
    "#       Summary:\n",
    "#       Term\t                        Purpose\t                          Used During Training?\n",
    "#       Training Set\t              Teach the model\t                              Yes\n",
    "#       Test Set\t                  Evaluate final model performance\t               No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a514d7-4174-4a74-bf1e-b5e4b20c7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. How do we split data for model fitting (training and testing) in Python?\n",
    "\n",
    "# Ans - Splitting data into training and testing sets in Python is commonly done using the train_test_split function from Scikit-learn \n",
    "#       (sklearn.model_selection). It’s simple and widely used.\n",
    "\n",
    "#      Parameters:\n",
    "#      test_size: Proportion of data for testing (e.g., 0.25 means 25% test, 75% train).\n",
    "#      train_size: Proportion for training (optional if test_size is set).\n",
    "#      random_state: Seed for reproducibility (keeps splits consistent across runs).\n",
    "#      shuffle: Whether to shuffle data before splitting (default is True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b679d-7cbd-446e-b5d3-80e2aaaf84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Why do we have to perform EDA before fitting a model to the data?\n",
    "\n",
    "# Ans -  Exploratory Data Analysis (EDA) is a crucial step before fitting any machine learning model, and here’s why:\n",
    "\n",
    "#        Why Perform EDA Before Modeling?\n",
    "\n",
    "#        1.Understand the Data\n",
    "#          Learn the structure, size, and types of data (numerical, categorical, missing values).\n",
    "#          Identify key features and target variables.\n",
    "\n",
    "#        2.Detect Data Quality Issues\n",
    "#          Find missing, incorrect, or inconsistent values.\n",
    "#          Spot outliers or anomalies that might skew the model.\n",
    "\n",
    "#        3.Reveal Patterns and Relationships\n",
    "#          Understand relationships between features and the target.\n",
    "#          Check correlations, distributions, and possible feature importance.\n",
    "\n",
    "#        4.Inform Data Cleaning and Preprocessing\n",
    "#          Decide how to handle missing data, encode categorical variables, scale features.\n",
    "#          Detect if transformations (log, scaling) are needed.\n",
    "\n",
    "#        5.Guide Feature Engineering\n",
    "#          Generate new meaningful features or reduce dimensionality.\n",
    "#          Select relevant features for better model performance.\n",
    "\n",
    "#        6.Choose Appropriate Models\n",
    "#          Knowing data characteristics helps pick algorithms that suit the problem.\n",
    "#          For example, linear vs nonlinear models, or classification vs regression.\n",
    "\n",
    "#        7.Prevent Waste of Time\n",
    "#          Avoid blindly training models on messy or uninformative data.\n",
    "#          EDA helps save time by highlighting problems upfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7988f-db93-474e-a060-28a427ac8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. How can you find correlation between variables in Python?\n",
    "\n",
    "# Ans - You can easily find the correlation between variables in Python using libraries like Pandas and NumPy. The most common method is calculating the \n",
    "#       Pearson correlation coefficient, which measures linear correlation.\n",
    "\n",
    "#       Other correlation methods available with corr():\n",
    "\n",
    "#       Pearson (default): measures linear relationship.\n",
    "#       Spearman: measures monotonic relationship, useful for non-linear.\n",
    "#       Kendall: another rank-based correlation measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a97cf-dd5d-4200-889f-a2abd64db107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. What is causation? Explain difference between correlation and causation with an example.\n",
    "\n",
    "# Ans - Causation means that one variable directly affects another — a change in one causes a change in the other.\n",
    "#       In simple terms:\n",
    "#       Causation = Cause and Effect\n",
    "\n",
    "#       Difference Between Correlation and Causation\n",
    "\n",
    "#       Concept\t                             Meaning\t                                                        Relationship\n",
    "#     Correlation\t               Two variables move together (positive or negative)\t             May or may not have a cause-effect link\n",
    "#      Causation\t               One variable causes the change in another\t                     Direct cause-effect relationship\n",
    "\n",
    "#      Finally we can say Correlation is a statistical association; causation is a proven effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae847930-6ae6-4451-af32-aeddc238dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "\n",
    "# Ans - In machine- and deep-learning, an optimizer is the algorithm that updates a model’s trainable parameters (weights & biases) in order to minimize\n",
    "#       the loss function.Given the gradient of the loss with respect to each parameter, an optimizer decides how big a step to take and, sometimes, \n",
    "#       in what direction beyond the raw gradient itself.\n",
    "\n",
    "#       Types of Optimizers with Examples\n",
    "\n",
    "#       1. Gradient Descent (GD)\n",
    "#          θ=θ−η⋅∇ θJ(θ) \n",
    "\n",
    "#          where:\n",
    "#         θ: model parameters\n",
    "#         η: learning rate\n",
    "#         J(θ): loss function\n",
    "\n",
    "#         Simple but slow; used mainly for teaching.\n",
    "\n",
    "#       2. Stochastic Gradient Descent (SGD)\n",
    "#          Idea: Instead of computing gradients on the full dataset, use a random mini-batch of data.\n",
    "#          Advantage: Faster and can escape local minima.\n",
    "\n",
    "#       3. SGD with Momentum\n",
    "#          Idea: Adds a velocity term that helps smooth updates.\n",
    "#          Benefit: Avoids zig-zag in gradients; accelerates training.\n",
    "\n",
    "#       4. Nesterov Accelerated Gradient (NAG)\n",
    "#          Idea: Looks ahead by applying momentum before calculating the gradient.\n",
    "#          Benefit: More responsive to changes in direction.\n",
    "\n",
    "#       5. RMSProp\n",
    "#          Idea: Uses exponentially decaying average of squared gradients for each parameter.\n",
    "#          Best For: Non-stationary problems like RNNs.\n",
    "\n",
    "#       6. AdaDelta\n",
    "#          Improvement over: Adagrad; avoids decaying learning rate problem.\n",
    "#          Rarely used today, but may be seen in older models.\n",
    "\n",
    "#       7. Lion (2023, Meta AI)\n",
    "#          Idea: Uses the sign of gradients instead of values for better memory efficiency.\n",
    "#          Performance: Matches or exceeds Adam, with lower memory cost.\n",
    "\n",
    "#       8. AdamW (Adam with Weight Decay)\n",
    "#          Idea: Improves Adam by decoupling weight decay (regularization).\n",
    "#          Used In: Transformers (e.g., BERT, GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b816a9d-2010-4d3c-9830-b90565271ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. What is sklearn.linear_model ?\n",
    "\n",
    "# Ans - sklearn.linear_model is a module in the Scikit-learn library (sklearn) that provides a collection of linear models for regression and \n",
    "#       classification tasks.These models assume a linear relationship between the input variables (features) and the output (target) — either directly \n",
    "#       or after applying some transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ef590-b9bb-46c3-b0bd-d3ff993cb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. What does model.fit() do? What arguments must be given?\n",
    "\n",
    "# Ans - model.fit() is a core function in machine learning models (especially in Scikit-learn) that trains the model using the given input data and \n",
    "#       target values.\n",
    "\n",
    "#       In simple terms: model.fit(X, y) tells the model to learn from the features X and labels y.\n",
    "\n",
    "#       Required Arguments\n",
    "#        model.fit(X, y)\n",
    "\n",
    "#       Argument\t                                               Description\n",
    "#         X\t                                     Input features (2D array-like: shape [n_samples, n_features])\n",
    "#         y\t                                     Target values (1D or 2D array: shape [n_samples])\n",
    "\n",
    "#      Function\t                                                     Role\n",
    "#      fit(X, y)\t                             Trains the model using input data and labels\n",
    "#     predict(X)\t                             Makes predictions on new input data after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae018e0-6905-40bd-bc74-c8ae459ad453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. What does model.predict() do? What arguments must be given?\n",
    "\n",
    "# Ans - model.predict() is used to make predictions using a trained machine learning model.After a model has been trained with .fit(X, y), we use \n",
    "#       .predict(X_new) to generate output predictions for new input data.\n",
    "\n",
    "#       Required Argument\n",
    "#       model.predict(X_new)\n",
    "#       Argument\t                                                        Description\n",
    "#        X_new\t                    Input features for which predictions are needed. Must be array-like with shape (n_samples, n_features) — just like \n",
    "#                                   the training features.\n",
    "\n",
    "#        Function\t                                                           Role\n",
    "#        fit(X, y)\t                                                    Trains the model\n",
    "#     predict(X_new)\t                                            Predicts output for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f333c-32be-461e-9fdd-d307f08e413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. What are continuous and categorical variables?\n",
    "\n",
    "# Ans - In machine learning and statistics, variables (also called features or attributes) can be classified into two main types:\n",
    "\n",
    "#       1. Continuous Variables\n",
    "#          Definition: Variables that can take any numeric value within a range, including fractions and decimals.\n",
    "#          Type: Quantitative (measurable)\n",
    "\n",
    "#          Examples:\n",
    "#          Temperature: 23.4°C\n",
    "#          Height: 170.5 cm\n",
    "#          Weight: 62.8 kg\n",
    "#          Income: $55,000.25\n",
    "#          Used in regression problems\n",
    "\n",
    "#       2. Categorical Variables\n",
    "#          Definition: Variables that represent categories or groups. They may or may not have a meaningful order.\n",
    "#          Type: Qualitative (descriptive)\n",
    "\n",
    "#          Examples:\n",
    "#          Gender: Male, Female\n",
    "#          Color: Red, Green, Blue\n",
    "#          Education Level: High School, Bachelor’s, Master’s\n",
    "#          Yes/No answers\n",
    "#          Used in classification problems\n",
    "\n",
    "#          Summary Table\n",
    "#         Variable Type\t                      Values\t               Example\t                   Problem Type\n",
    "#          Continuous\t                   Real numbers\t           Height = 172.5 cm\t            Regression\n",
    "#       Categorical (Nominal)\t        Categories (unordered)\t   Gender = Male\t               Classification\n",
    "#        Categorical (Ordinal)\t         Categories (ordered)\t       Rank = High,                    Low\tClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718660e0-a618-4472-820d-28ae6f43f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. What is Feature Scaling?\n",
    "\n",
    "# Ans - Feature scaling is the process of normalizing or standardizing the range of independent variables (features) in your dataset, so they are on a\n",
    "#       similar scale.It ensures that no feature dominates others due to differences in units or magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879deda1-719f-408c-afbd-19627908d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. How do we perform scaling in Python?\n",
    "\n",
    "# Ans - We can scale your data using preprocessing classes from the sklearn.preprocessing module.\n",
    "\n",
    "#       1. Using StandardScaler (Standardization)\n",
    "#          Transforms data to have mean = 0 and standard deviation = 1.\n",
    "#          Best for features with normal (Gaussian) distribution.\n",
    "\n",
    "#       2. Using MinMaxScaler (Normalization)\n",
    "#          Scales features to a fixed range, usually [0, 1].\n",
    "#          Good for non-Gaussian data or when features must be bounded.\n",
    "\n",
    "#       3. Using RobustScaler (for outliers)\n",
    "#          Uses median and interquartile range.\n",
    "#          More robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e228c2-aaef-4010-8509-346eacc6fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. What is sklearn.preprocessing?\n",
    "\n",
    "# Ans - sklearn.preprocessing is a module in Scikit-learn that provides a variety of tools to prepare and transform your data before feeding it into a \n",
    "#       machine learning model.Preprocessing is a critical step that improves model performance, accuracy, and convergence speed.\n",
    "\n",
    "#       1. Feature Scaling\n",
    "#          Normalize or standardize features to a similar range or distribution.\n",
    "\n",
    "#       2. Encoding Categorical Variables\n",
    "#          Convert categorical (text or label) data into numerical format.\n",
    "\n",
    "#       3. Binarization\n",
    "#          Convert numeric values into 0s and 1s based on a threshold.\n",
    "\n",
    "#       4. Polynomial Features\n",
    "#          Generate new features by combining existing ones in polynomial form.\n",
    "\n",
    "#       5. Normalization\n",
    "#          Scale individual samples (rows) to have unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fea8c3-3b55-453c-ad18-0cd73c461448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. How do we split data for model fitting (training and testing) in Python?\n",
    "\n",
    "# Ans - In machine learning, it's important to split your dataset into:\n",
    "#       Training set: To train the model.\n",
    "#       Testing set: To evaluate the model’s performance on unseen data.\n",
    "\n",
    "#       Key Parameters of train_test_split\n",
    "\n",
    "#       Parameter\t                           Description\t                                         Example\n",
    "#       test_size\t                   Fraction or number for test set size\t                      0.2 (20% test)\n",
    "#       train_size\t                   Fraction or number for train set size (optional)\t          0.8 (80% train)\n",
    "#       random_state\t               Seed for reproducibility\t                                  42 (fixed split every run)\n",
    "#       shuffle\t                       Whether to shuffle before splitting\t                      Default is True\n",
    "\n",
    "#       To avoid overfitting by testing on data the model hasn’t seen.\n",
    "#       To get an unbiased estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754738d9-c4d8-467b-9c0f-6c01e47389b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. Explain data encoding?\n",
    "\n",
    "# Ans - Data encoding is the process of transforming categorical (non-numeric) data into numerical format so machine learning models can understand and\n",
    "#       use it.Most ML algorithms work only with numbers, so encoding categorical variables is a crucial preprocessing step.\n",
    "\n",
    "#       Why Encode Data?\n",
    "#       ML models can’t directly handle text labels or categories.\n",
    "#       Encoding converts categories into numbers without losing the meaning.\n",
    "#       Helps algorithms learn patterns from categorical features.\n",
    "\n",
    "#       Label Encoding: Good for ordinal data or when categories have order.\n",
    "#       One-Hot Encoding: Preferred for nominal data with no natural order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
